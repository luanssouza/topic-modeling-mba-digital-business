{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKxeTCyxpRjN"
      },
      "source": [
        "# B2W-Reviews01\n",
        "\n",
        "More information: https://github.com/americanas-tech/b2w-reviews01/blob/main/README.md"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "csRgAXMZqZIy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tcZU4z4F8cg"
      },
      "outputs": [],
      "source": [
        "## If you are using a Folder on Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "folder = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HKa3qqzGZ_R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')"
      ],
      "metadata": {
        "id": "ujS94OAxfDhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "DlA-JqsofGfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "import json\n",
        "import math\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "HC9g82sMfK3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import LdaModel\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.test.utils import datapath"
      ],
      "metadata": {
        "id": "akm3vfsjmLR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_lg -q"
      ],
      "metadata": {
        "id": "YxXv5NyIn6M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_lg\")"
      ],
      "metadata": {
        "id": "TIHSSzoNoGgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZndDX78_GBvu"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(folder + 'B2W-Reviews01TextSentiments.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjvkHFjGj7w7"
      },
      "source": [
        "## Processing user reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topic Modelling\n"
      ],
      "metadata": {
        "id": "OzqVF-5bqM0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions"
      ],
      "metadata": {
        "id": "Jw_lxqh3mgBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_corpus(docs):\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  for idx in range(len(docs)):\n",
        "      docs[idx] = docs[idx].lower()\n",
        "      docs[idx] = tokenizer.tokenize(docs[idx])\n",
        "\n",
        "  docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
        "\n",
        "  docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
        "\n",
        "  bigram = Phrases(docs, min_count=20)\n",
        "  for idx in range(len(docs)):\n",
        "      for token in bigram[docs[idx]]:\n",
        "          if '_' in token:\n",
        "              docs[idx].append(token)\n",
        "\n",
        "  dictionary = Dictionary(docs)\n",
        "\n",
        "  dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
        "\n",
        "  corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
        "\n",
        "  return dictionary, corpus, docs"
      ],
      "metadata": {
        "id": "bDD9cKDfmgcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(corpus, dictionary, num_topics):\n",
        "  dictionary[0]\n",
        "  return LdaModel(corpus=corpus, id2word=dictionary.id2token, num_topics=num_topics)"
      ],
      "metadata": {
        "id": "0bd_gV6QpmXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topics_cloud(topics):\n",
        "  topics_cloud = { w: v for v, w in topics}\n",
        "\n",
        "  wordcloud = WordCloud(collocations = False, background_color = 'white')\n",
        "  wordcloud.generate_from_frequencies(frequencies=topics_cloud)\n",
        "  plt.figure()\n",
        "  plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "98WPz2omnTXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_word_clouds(topics, rows, cols, i = 0, figsize=None, title='', file_name=None):\n",
        "\n",
        "  figure, axis = plt.subplots(rows, cols, figsize=figsize)\n",
        "\n",
        "  n_topics = len(topics)\n",
        "\n",
        "  for r in range(rows):\n",
        "    for c in range(cols):\n",
        "      ax = axis\n",
        "      if rows > 1 and cols > 1:\n",
        "        ax = axis[r, c]\n",
        "      elif rows > 1:\n",
        "        ax = axis[r]\n",
        "      elif cols > 1:\n",
        "        ax = axis[c]\n",
        "      else:\n",
        "        ax = axis\n",
        "      ax.axis(\"off\")\n",
        "\n",
        "      if i >= n_topics:\n",
        "        continue\n",
        "\n",
        "      topics_cloud = { w: v for v, w in topics[i][0]}\n",
        "      if file_name:\n",
        "        wordcloud = WordCloud(width=2000, height=1000, collocations = False, background_color = 'white')\n",
        "      else:\n",
        "        wordcloud = WordCloud(collocations = False, background_color = 'white')\n",
        "      wordcloud.generate_from_frequencies(frequencies=topics_cloud)\n",
        "\n",
        "      ax.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "      ax.set_title(\"Tópico %d\" % i)\n",
        "      ax.axis(\"off\")\n",
        "\n",
        "      i += 1\n",
        "\n",
        "  figure.suptitle(('Tópicos %s' % title).strip())\n",
        "\n",
        "  if file_name:\n",
        "    plt.savefig(file_name, dpi=600, bbox_inches='tight', pad_inches = 0)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "3rFF_HwzxE1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting Model"
      ],
      "metadata": {
        "id": "IU84VOfolfNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.review_lemmas.isna() == False].copy()\n",
        "docs = list(df.review_lemmas)\n",
        "\n",
        "dictionary, corpus, docs = process_corpus(docs)\n",
        "\n",
        "print('Number of unique tokens: %d' % len(dictionary))\n",
        "print('Number of documents: %d' % len(corpus))"
      ],
      "metadata": {
        "id": "zEKwzpIphWEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "for n in range(2, 21, 2):\n",
        "  model = create_model(corpus, dictionary, n)\n",
        "  coherence = CoherenceModel(model=model, corpus=corpus, coherence='c_v', texts=docs, dictionary=dictionary).get_coherence()\n",
        "  perplexity = model.log_perplexity(corpus)\n",
        "  models.append((n, model, coherence, perplexity))\n",
        "  print('Average topic coherence: %.4f. Perplexity: %.4f. Number of topics: %d' % (coherence, perplexity, n))"
      ],
      "metadata": {
        "id": "Qy0FsSJvypo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([(n,c,p) for n,_,c,p in models], columns=['Number of topics', 'Coherence', 'Perplexity'])"
      ],
      "metadata": {
        "id": "xzs87X7zw8TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_y = [ p for _,_,_,p in models]\n",
        "c_y = [ c for _,_,c,_ in models]\n",
        "n = [ n for n,_,_,_ in models]"
      ],
      "metadata": {
        "id": "KONQO1XfO7c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(10,3))\n",
        "\n",
        "ax[0].plot(n, c_y)\n",
        "ax[0].set_title('Coherence')\n",
        "ax[0].set_xlabel('Number of Topics')\n",
        "ax[0].set_ylabel('Score')\n",
        "\n",
        "ax[1].plot(n, p_y)\n",
        "ax[1].set_title('Perplexity')\n",
        "ax[1].set_xlabel('Number of Topics')\n",
        "ax[1].set_ylabel('Score')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Gdogvn_O26v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_model = models[4]\n",
        "model = selected_model[1]\n",
        "coherence = selected_model[2]\n",
        "perplexity = selected_model[3]\n",
        "print('Average topic coherence: %.4f. Perplexity: %.4f. Number of topics: %d' % (coherence, perplexity, selected_model[0]))"
      ],
      "metadata": {
        "id": "h3vHJXcHQnQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_topics = model.top_topics(corpus)"
      ],
      "metadata": {
        "id": "iUanIq7usKwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_word_clouds(top_topics, 2, 5, 0, (15, 4), 'Geral', 'topicscloud.png')"
      ],
      "metadata": {
        "id": "v4PgVHlRV04Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis"
      ],
      "metadata": {
        "id": "i85cqCOlXa_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions"
      ],
      "metadata": {
        "id": "t3USHaPdZX4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_sentiment(word, df, index=None):\n",
        "  word_sent_df = df.loc[index] if index else df\n",
        "  word_sent_df = word_sent_df[[True if word in r else False for r in word_sent_df.review_lemmas]]\n",
        "\n",
        "  leng = len(word_sent_df)\n",
        "\n",
        "  if leng == 0:\n",
        "    return 0, 0, 0\n",
        "\n",
        "  pos = word_sent_df[word_sent_df.review_sent_label == 'Positive'].review_sent_score.sum() / leng\n",
        "  neg = word_sent_df[word_sent_df.review_sent_label == 'Negative'].review_sent_score.sum() / leng\n",
        "  neu = word_sent_df[word_sent_df.review_sent_label == 'Neutral'].review_sent_score.sum() / leng\n",
        "\n",
        "  return pos, neg, neu"
      ],
      "metadata": {
        "id": "nxbGuJ3ldCbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topic_sentiment(words_sentiment, top_topics, sentiment='positive'):\n",
        "  topics_sentiments = []\n",
        "  for t in top_topics:\n",
        "    sent = 0\n",
        "    for w in t[0]:\n",
        "      if w[1] not in words_sentiment.keys():\n",
        "        continue\n",
        "      if sentiment == 'overall':\n",
        "        sent += words_sentiment[w[1]]['positive'] - words_sentiment[w[1]]['negative']\n",
        "      else:\n",
        "        sent += words_sentiment[w[1]][sentiment]\n",
        "    topics_sentiments.append(sent / len(t[0]))\n",
        "\n",
        "  return topics_sentiments"
      ],
      "metadata": {
        "id": "0N7CZzLngbhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_qtd_sentiment(word, df, index=None):\n",
        "  df = df.loc[index] if index else df\n",
        "  word_sent_df = df[[True if word in r else False for r in df.review_lemmas]]\n",
        "  word_sent_df = word_sent_df.groupby('review_sent_label')['review_sent_label'].count()\n",
        "\n",
        "  sentiments = [0, 0, 0]\n",
        "  for s in word_sent_df.index:\n",
        "\n",
        "    if s == 'Positive':\n",
        "      sentiments[0] = word_sent_df.loc['Positive']\n",
        "    elif s == 'Negative':\n",
        "      sentiments[1] = word_sent_df.loc['Negative']\n",
        "    elif s == 'Neutral':\n",
        "      sentiments[2] = word_sent_df.loc['Neutral']\n",
        "\n",
        "  return sentiments"
      ],
      "metadata": {
        "id": "mHX_6JzwdyNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topic_qtd_sentiment(words_sentiment, top_topics, sentiment='positive'):\n",
        "  topics_sentiments = []\n",
        "  for t in top_topics:\n",
        "    sent = 0\n",
        "    for w in t[0]:\n",
        "      if w[1] not in words_sentiment.keys():\n",
        "        continue\n",
        "      if sentiment == 'overall':\n",
        "        sent += words_sentiment[w[1]]['positive'] + words_sentiment[w[1]]['negative'] + words_sentiment[w[1]]['neutral']\n",
        "      else:\n",
        "        sent += words_sentiment[w[1]][sentiment]\n",
        "    topics_sentiments.append(sent)\n",
        "\n",
        "  return topics_sentiments"
      ],
      "metadata": {
        "id": "ml8OFRSadyNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Applying Sentiment Analysis"
      ],
      "metadata": {
        "id": "1zCICq9OZfJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_sentiment = {}\n",
        "dictionary[0]\n",
        "for _,w in dictionary.id2token.items():\n",
        "  pos, neg, neu = word_sentiment(w, df)\n",
        "  words_sentiment[w] = { 'positive': pos, 'negative': neg, 'neutral': neu }"
      ],
      "metadata": {
        "id": "Vhgk6GzqeEyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(10), topic_sentiment(words_sentiment, top_topics, sentiment='positive'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iIEt4oQSpN2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(10), topic_sentiment(words_sentiment, top_topics, sentiment='negative'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4ya2M4rUqR1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(range(10), topic_sentiment(words_sentiment, top_topics, sentiment='overall'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VO9fXnExp7-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(topic_sentiment(words_sentiment, top_topics, sentiment='overall'), columns=['Overall Sentiment'])"
      ],
      "metadata": {
        "id": "ARarK-dcSE6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_qtd_sentiment = {}\n",
        "dictionary[0]\n",
        "for _,w in dictionary.id2token.items():\n",
        "  pos, neg, neu = word_qtd_sentiment(w, df)\n",
        "  words_qtd_sentiment[w] = { 'positive': pos, 'negative': neg, 'neutral': neu }"
      ],
      "metadata": {
        "id": "AOKfvPkidyNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = 0.25\n",
        "multiplier = 0\n",
        "offset = width * multiplier\n",
        "plt.bar(np.arange(10) + offset, topic_qtd_sentiment(words_qtd_sentiment, top_topics, sentiment='positive'), width, label='Positive', color=['tab:green'])\n",
        "\n",
        "multiplier += 1\n",
        "offset = width * multiplier\n",
        "plt.bar(np.arange(10) + offset, topic_qtd_sentiment(words_qtd_sentiment, top_topics, sentiment='negative'), width, label='Negative', color=['tab:red'])\n",
        "\n",
        "multiplier += 1\n",
        "offset = width * multiplier\n",
        "plt.bar(np.arange(10) + offset, topic_qtd_sentiment(words_qtd_sentiment, top_topics, sentiment='neutral'), width, label='Neutral', color=['tab:blue'])\n",
        "\n",
        "plt.legend(loc='upper left', ncols=3)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xg721Cfceliq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_qtd_sentiment_dict =  {\n",
        "    'Positive': topic_qtd_sentiment(words_qtd_sentiment, top_topics, sentiment='positive'),\n",
        "    'Negative': topic_qtd_sentiment(words_qtd_sentiment, top_topics, sentiment='negative'),\n",
        "    'Neutral': topic_qtd_sentiment(words_qtd_sentiment, top_topics, sentiment='neutral')\n",
        "}\n",
        "pd.DataFrame(topic_qtd_sentiment_dict)"
      ],
      "metadata": {
        "id": "dzwwKFyOktfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End"
      ],
      "metadata": {
        "id": "Hlf_qbUsZyAo"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}